{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1B_g8ZzAZ7LKWxXxBlKNcsgISlNOHw5f2",
      "authorship_tag": "ABX9TyPa28zpGgD5CFWEpCfFuYrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANITHAKISHORE/EDA/blob/main/Internship_Assignment_for_NLP(Voice_AI)_Creation_of_for_Speech_to_Text_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5FSC8G_8CfKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE6We6v7As9H",
        "outputId": "2ef94e93-625a-4313-9d6e-d0d633fc3224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSOTi3yZNML9"
      },
      "outputs": [],
      "source": [
        "!pip3 install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install Transformers"
      ],
      "metadata": {
        "id": "KyYHgHWz2Khi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install datasets"
      ],
      "metadata": {
        "id": "KqjBlKPo2Kze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install accelerate"
      ],
      "metadata": {
        "id": "pLJzlm1o2K-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install whisper"
      ],
      "metadata": {
        "id": "LGABnJfcrNOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "mYS1CfDG2LPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(output[1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RXDNR96b0_G",
        "outputId": "edc3f2e8-4a86-45f6-f23f-8756688f01d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n"
      ],
      "metadata": {
        "id": "iyFSayVy2LTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, use_safetensors=True\n",
        ")"
      ],
      "metadata": {
        "id": "A5BXg6tb2LWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "AmniUkh-2LZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDqeFOVb28d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=30,\n",
        "    batch_size=16,\n",
        "    return_timestamps=\"word\",\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "HU7TZ0zd_Hbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import datasets\n",
        "\n",
        "dataset = datasets.load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
        "sample = dataset[0][\"audio\"]\n",
        "\n",
        "result = pipe(sample)\n",
        "print(result[\"text\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJlwK3633uOI",
        "outputId": "ba5c8b09-e165-4cc4-f0f5-63bc7f015abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL NOR IS MISTER QUILTER'S MANNER LESS INTERESTING THAN HIS MATTER HE TELLS US THAT AT THIS FESTIVE SEASON OF THE YEAR WITH CHRISTMS AND ROAST BEEF LOOMING BEFORE US SIMILES DRAWN FROM EATING AND ITS RESULTS OCCUR MOST READILY TO THE MIND HE HAS GRAVE DOUBTS WHETHER SIR FREDERICK LAYTON'S WORK IS READY GREEK AFTER ALL AND CAN DISCOVER IN IT BUT LITTLE OF ROCKY ITHACA LENELL'S PICTURES ARE A SORT OF UP GUARDS AND ADAM PAINTINGS AND MASON'S EXQUISITE IDLLS ARE AS NATIONAL AS A JINGO POEM MISTER BURKETT FOSTER'S LANDSCAPES SMILE AT ONE MUCH IN THE SAME WAY THAT MISTER CARKER USED TO FLASH HIS TEETH AND MISTER JOHN CAWLEYER GIVES HIS SIDER A CHEERFUL SLAP ON THE BACK BEFORE HE SAYS LIKE A SHAMPOOER IN A TURKISH BATH NEXT MAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = '/content/common_voice_mr_27591986.wav'\n",
        "result = pipe(sample)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfyDcAd6KwCQ",
        "outputId": "7e55b144-fcdf-48ec-f158-05a3a3d0e2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAR BY NATFULLY CUTIS WUL OBIE LA HOI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = '/content/common_voice_mr_27591987.wav'\n",
        "result = pipe(sample)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVkNGlfuKv4L",
        "outputId": "464cadb0-045e-40b0-82de-c823c06cbcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANAK RECHIMA ABUNGO GOENI AS HIS FOUT LECON DENNI GILLI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_wer(sample, result[\"text\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8Mksp6va4ML",
        "outputId": "31be09e5-60ec-443b-d532-c0e4375243cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for the ASR -- Automatic Speech Recognition is (WER) Word Error Rate, Character Error Rate (CER), Sentence Error Rate(SER)"
      ],
      "metadata": {
        "id": "94n-ymwma4GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YO31OCm_a357"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip3 install wer"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "wMM6uZlyedWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def calculate_wer(reference, result):\n",
        "  \"\"\"Calculates the word error rate (WER) between two strings.\n",
        "\n",
        "  Args:\n",
        "    reference: The reference string.\n",
        "    result: The result string.\n",
        "\n",
        "  Returns:\n",
        "    The WER.\n",
        "  \"\"\"\n",
        "\n",
        "  # Convert the strings to lists of words.\n",
        "  reference_words = reference.split()\n",
        "  result_words = result.split()\n",
        "\n",
        "  # Calculate the number of errors.\n",
        "  num_errors = 0\n",
        "  for i in range(len(reference_words)):\n",
        "    if reference_words[i] != result_words[i]:\n",
        "      num_errors += 1\n",
        "\n",
        "  # Calculate the WER.\n",
        "  wer = num_errors / len(reference_words)\n",
        "\n",
        "  return wer"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Vi0RbhradiiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ij1lvsot_vWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJ6uelPFGTSF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}